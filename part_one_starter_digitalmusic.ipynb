{"cells":[{"cell_type":"code","source":["# Activate Spark in our Colab notebook.\nimport os\n# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n# For example:\n# spark_version = 'spark-3.2.2'\nspark_version = 'spark-3.2.3'\nos.environ['SPARK_VERSION']=spark_version\n\n# Install Spark and Java\n!apt-get update\n!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n!pip install -q findspark\n\n# Set Environment Variables\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n\n# Start a SparkSession\nimport findspark\nfindspark.init()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8eFW_wl1n39","outputId":"9a3c780e-fa40-416c-c653-7e8254d85497","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"009369f4-daaa-42c9-8a2e-c4ca4e282d7c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://repos.azul.com/zulu/deb stable InRelease\r\n\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\r\n\r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\r\n\r                                              \r0% [Waiting for headers]\r                        \rHit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\r\n\r0% [Waiting for headers]\r0% [Waiting for headers]\r                        \rHit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\r\n\r                        \r0% [Working]\r0% [Working]\r0% [Working]\r20% [Working]\r             \r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 4%\r\rReading package lists... 4%\r\rReading package lists... 5%\r\rReading package lists... 5%\r\rReading package lists... 48%\r\rReading package lists... 48%\r\rReading package lists... 49%\r\rReading package lists... 49%\r\rReading package lists... 50%\r\rReading package lists... 60%\r\rReading package lists... 60%\r\rReading package lists... 69%\r\rReading package lists... 69%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 84%\r\rReading package lists... 84%\r\rReading package lists... 92%\r\rReading package lists... 92%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 99%\r\rReading package lists... 99%\r\rReading package lists... Done\r\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 23.0.1 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"]}],"execution_count":0},{"cell_type":"code","source":["# Get postgresql package\n!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzCrgs0Z1rnw","outputId":"ec69bc40-e6fc-4df3-a738-9d90f097775a","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d63b8cae-d5e3-4c6b-a77e-55c8cb899c09","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["--2023-03-16 06:49:13--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\r\nResolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\r\nConnecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 914037 (893K) [application/java-archive]\r\nSaving to: ‘postgresql-42.2.9.jar.4’\r\n\r\n\rpostgresql-42.2.9.j   0%[                    ]       0  --.-KB/s               \rpostgresql-42.2.9.j  20%[===>                ] 183.71K   710KB/s               \rpostgresql-42.2.9.j  54%[=========>          ] 487.71K   944KB/s               \rpostgresql-42.2.9.j 100%[===================>] 892.61K  1.50MB/s    in 0.6s    \r\n\r\n2023-03-16 06:49:14 (1.50 MB/s) - ‘postgresql-42.2.9.jar.4’ saved [914037/914037]\r\n\r\n"]}],"execution_count":0},{"cell_type":"code","source":["# Import Spark and create a SparkSession\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"BigData-HW-1\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"],"metadata":{"id":"0DuBth0V2PR8","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8cfefb38-34cf-4331-9dd0-df803541ba5f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Extract the Amazon Data into Spark DataFrame"],"metadata":{"id":"D3W2XJVi2CU-","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c1df816-2c55-43cc-ab3d-a3c11f0327d3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Read in the data from an S3 Bucket\nfrom pyspark import SparkFiles\nurl = \"s3://bigdata-etl-randie/amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv\"\nspark.sparkContext.addFile(url)\n\ndf = spark.read.option('header', 'true').csv(url, sep='\\t', inferSchema=True)\ndf.show(20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Na_stw7b1wfU","outputId":"5b1ef517-c203-47d2-abc2-aca40b24098d","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8ad69a0c-212f-4944-9220-76a5bb311f5c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+-----------+--------------+----------+--------------+--------------------+--------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|    product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n+-----------+-----------+--------------+----------+--------------+--------------------+--------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n|         US|   10293599|R14LVB34Z2Z53I|B000YMOQZY|     262935067|Knockin' On Heave...|Digital_Music_Pur...|          5|            0|          0|   N|                Y|           favorites|Great  rendition....| 2015-08-31|\n|         US|    6087195|R2M0R9CWPC82LT|B00ISAEC80|     452318038|            Flawless|Digital_Music_Pur...|          5|            0|          0|   N|                Y|          Five Stars|A good music to l...| 2015-08-31|\n|         US|   33717063| RQNQI2R3BM52A|B00VBB6AVU|     675969129|    Scandal of Grace|Digital_Music_Pur...|          4|            0|          0|   N|                Y|                Good|Not as good as th...| 2015-08-31|\n|         US|   14948020| RTUIX1135HUAB|B008A5POJO|     282925893|  I Surrender (Live)|Digital_Music_Pur...|          5|            0|          0|   N|                Y|Wonderful lyrics!...|Time to worship a...| 2015-08-31|\n|         US|   21694522| RE3QSAT8TL010|B014CW2RN4|     109077793|We Are Young (Jer...|Digital_Music_Pur...|          4|            0|          0|   N|                Y|Hot remix but too...|So this should be...| 2015-08-31|\n|         US|   14948020|R14TN65IY0NUOD|B00DRA3EOY|     959245080|        Lord, I Live|Digital_Music_Pur...|          5|            0|          0|   N|                Y|          Five Stars|Clint Brown is an...| 2015-08-31|\n|         US|   20031966|R3LIF8MCNH1ODF|B009G3U0PW|     762436916|  I'll Never Be Free|Digital_Music_Pur...|          5|            0|          0|   N|                Y|\"I'll never be fr...|LaVerne Butler is...| 2015-08-31|\n|         US|   12223745|R33X0DGA4PPQ3L|B013XBYQOS|     137980344|    All of the Stars|Digital_Music_Pur...|          5|            3|          3|   N|                N| long awaited treat!|For some reason I...| 2015-08-31|\n|         US|   30231876|R2DJJP7DQRT1ZW|B003L5H25W|     165995375|Exile On Main Str...|Digital_Music_Pur...|          5|            0|          1|   N|                Y|          Five Stars|The Stones at the...| 2015-08-31|\n|         US|   51714365|R2A8XDXW5XOT4H|B00136NVH4|     227508666|     Bat Out Of Hell|Digital_Music_Pur...|          5|            0|          0|   N|                Y|    Transcends Time.|    Simply the best.| 2015-08-31|\n|         US|   37216001|R3MJK3L7ER61TT|B0030AKPQ6|     164096943|Stronger Than Her...|Digital_Music_Pur...|          5|            0|          0|   N|                N|I Love The Flirta...|A very early hit ...| 2015-08-31|\n|         US|   49207156|R38Z7XMCVDR0R5|B014EQE0V0|     714368268|You Hold It All (...|Digital_Music_Pur...|          5|            1|          1|   N|                Y|          Five Stars|Inspired by this ...| 2015-08-31|\n|         US|    2472364|R3FFESBQXPR7S6|B00USW4ZVU|      50310906|   Pressure - Single|Digital_Music_Pur...|          4|            0|          0|   N|                Y|Talented new gosp...|Great new artist....| 2015-08-31|\n|         US|   22612468|R3QO6Z942CKH34|B00ZZDJAX0|     162295903|What Are The Chan...|Digital_Music_Pur...|          5|            1|          1|   N|                Y|        Awesome song|Great song off th...| 2015-08-31|\n|         US|    2254795|R297119MDWMG9P|B014DIWONU|      44838453|Beauty Behind The...|Digital_Music_Pur...|          5|            0|          0|   N|                Y|I love every song...|The weeknd is a m...| 2015-08-31|\n|         US|   12408664| R7EJRSXIXMLIY|B005DPTQNE|     454271984|It's The Huck-A-B...|Digital_Music_Pur...|          5|            0|          0|   N|                Y|          Five Stars|       Sounds great!| 2015-08-31|\n|         US|   36236254|R2EBGPZD0B3TSV|B004LI9ATO|     519024911|  Two Purple Shadows|Digital_Music_Pur...|          5|            0|          0|   N|                N|An oldie,,, but i...|An oldie , , , bu...| 2015-08-31|\n|         US|   10456004|R229VSSFBNB90C|B00984QCM4|     647155979|         Consolation|Digital_Music_Pur...|          5|            0|          0|   N|                Y|          Five Stars|               great| 2015-08-31|\n|         US|   16822806|R12YCDYTDBJH3X|B00ZKCAK4O|     346522639|One Man Army [Exp...|Digital_Music_Pur...|          5|            0|          0|   N|                Y|One Man Army! Dow...|Real Sh*t Right H...| 2015-08-31|\n|         US|   30704319|R3DEVUNGQ2Y98S|B014GWCW8K|     260814213|Without You (feat...|Digital_Music_Pur...|          5|            0|          0|   N|                Y|          Five Stars|      Press Forward!| 2015-08-31|\n+-----------+-----------+--------------+----------+--------------+--------------------+--------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Get the number of rows in the DataFrame.\ndf.count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cayz-3Q52IM3","outputId":"5d19aeec-223a-4372-f773-f74ab1aabc62","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f638bd6c-a7c8-4209-a066-aa2852cd2750","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[67]: 1688884"]}],"execution_count":0},{"cell_type":"markdown","source":["# Transform the Data"],"metadata":{"id":"C9U0rkGZ2eu7","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3d32962-5517-451c-aee8-e5be34ca43d5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Examine the Schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae45ce87-f3d0-4776-ad46-0acd8496a5b9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"515f22b3-6c1c-4edf-aaa0-b79ea81312bf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- marketplace: string (nullable = true)\n |-- customer_id: integer (nullable = true)\n |-- review_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- product_parent: integer (nullable = true)\n |-- product_title: string (nullable = true)\n |-- product_category: string (nullable = true)\n |-- star_rating: integer (nullable = true)\n |-- helpful_votes: integer (nullable = true)\n |-- total_votes: integer (nullable = true)\n |-- vine: string (nullable = true)\n |-- verified_purchase: string (nullable = true)\n |-- review_headline: string (nullable = true)\n |-- review_body: string (nullable = true)\n |-- review_date: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"review_id_table\"."],"metadata":{"id":"dUoftWoKtM_c","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"73f7fe05-6f1c-4bce-b8e2-eeeed5a44377","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import to_date\n# Create the \"review_id_df\" DataFrame with the appropriate columns and data types.\nreview_id_table = df.select([\"review_id\",\"customer_id\",\"product_id\", \"product_parent\",\"review_date\"])\nreview_id_table.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tMYkSIk2d-m","outputId":"e090226f-d7f3-4319-c47f-8a4fc9a69c09","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5c9163d6-d607-4d18-bfa9-fc7de5c61335","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------+-----------+----------+--------------+-----------+\n|     review_id|customer_id|product_id|product_parent|review_date|\n+--------------+-----------+----------+--------------+-----------+\n|R14LVB34Z2Z53I|   10293599|B000YMOQZY|     262935067| 2015-08-31|\n|R2M0R9CWPC82LT|    6087195|B00ISAEC80|     452318038| 2015-08-31|\n| RQNQI2R3BM52A|   33717063|B00VBB6AVU|     675969129| 2015-08-31|\n| RTUIX1135HUAB|   14948020|B008A5POJO|     282925893| 2015-08-31|\n| RE3QSAT8TL010|   21694522|B014CW2RN4|     109077793| 2015-08-31|\n|R14TN65IY0NUOD|   14948020|B00DRA3EOY|     959245080| 2015-08-31|\n|R3LIF8MCNH1ODF|   20031966|B009G3U0PW|     762436916| 2015-08-31|\n|R33X0DGA4PPQ3L|   12223745|B013XBYQOS|     137980344| 2015-08-31|\n|R2DJJP7DQRT1ZW|   30231876|B003L5H25W|     165995375| 2015-08-31|\n|R2A8XDXW5XOT4H|   51714365|B00136NVH4|     227508666| 2015-08-31|\n|R3MJK3L7ER61TT|   37216001|B0030AKPQ6|     164096943| 2015-08-31|\n|R38Z7XMCVDR0R5|   49207156|B014EQE0V0|     714368268| 2015-08-31|\n|R3FFESBQXPR7S6|    2472364|B00USW4ZVU|      50310906| 2015-08-31|\n|R3QO6Z942CKH34|   22612468|B00ZZDJAX0|     162295903| 2015-08-31|\n|R297119MDWMG9P|    2254795|B014DIWONU|      44838453| 2015-08-31|\n| R7EJRSXIXMLIY|   12408664|B005DPTQNE|     454271984| 2015-08-31|\n|R2EBGPZD0B3TSV|   36236254|B004LI9ATO|     519024911| 2015-08-31|\n|R229VSSFBNB90C|   10456004|B00984QCM4|     647155979| 2015-08-31|\n|R12YCDYTDBJH3X|   16822806|B00ZKCAK4O|     346522639| 2015-08-31|\n|R3DEVUNGQ2Y98S|   30704319|B014GWCW8K|     260814213| 2015-08-31|\n+--------------+-----------+----------+--------------+-----------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"products\" Table"],"metadata":{"id":"aAVCFjXhtXO8","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"37315176-2e56-4333-a0fb-6f21db856b03","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Create the \"products_df\" DataFrame that drops the duplicates in the \"product_id\" and \"product_title columns. \nproducts_df = df.select([\"product_id\",\"product_title\"])\nproducts_df = products_df.dropDuplicates()\nproducts_df.show()"],"metadata":{"id":"g9gTNhT62je4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c6e97a7-c616-4229-e2f3-29e043b53833","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e8c5d4eb-f7e4-4f9e-8c55-2e8caafb9502","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+--------------------+\n|product_id|       product_title|\n+----------+--------------------+\n|B005DPTQNE|It's The Huck-A-B...|\n|B00W4T83JK|        Lose My Mind|\n|B00VBB6AVU|    Scandal of Grace|\n|B00136NVH4|     Bat Out Of Hell|\n|B003L5H25W|Exile On Main Str...|\n|B00ZZDJAX0|What Are The Chan...|\n|B013XBYQOS|    All of the Stars|\n|B004LI9ATO|  Two Purple Shadows|\n|B00984QCM4|         Consolation|\n|B014GWCW8K|Without You (feat...|\n|B008A5POJO|  I Surrender (Live)|\n|B0030AKPQ6|Stronger Than Her...|\n|B014EQE0V0|You Hold It All (...|\n|B00ZKCAK4O|One Man Army [Exp...|\n|B00DRA3EOY|        Lord, I Live|\n|B00ISAEC80|            Flawless|\n|B014CW2RN4|We Are Young (Jer...|\n|B000YMOQZY|Knockin' On Heave...|\n|B009G3U0PW|  I'll Never Be Free|\n|B014DIWONU|Beauty Behind The...|\n+----------+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"customers\" Table"],"metadata":{"id":"LJHuZ9zut0e5","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c4dcd777-53cd-4af1-8807-ddde6c49be90","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import count\nfrom pyspark.sql.functions import desc\n\n# Create the \"customers_df\" DataFrame that groups the data on the \"customer_id\" by the number of times a customer reviewed a product. \ncustomers_df = df.groupBy(\"customer_id\").agg(count(\"*\").alias(\"customer_count\"))\ncustomers_df = customers_df.orderBy(desc(\"customer_count\"))\ncustomers_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pF2Vf3c2n2O","outputId":"9214d06e-83e1-40cf-d209-e1a571ba03cc","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e36df0d-3626-4e68-9eaa-4f31e0bfdd18","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+\n|customer_id|customer_count|\n+-----------+--------------+\n|    7080939|          1907|\n|   42418272|          1821|\n|   29274627|           802|\n|   53037408|           667|\n|   22015347|           618|\n|   35193692|           611|\n|   34633160|           576|\n|   14314332|           557|\n|   26687122|           530|\n|   34376725|           468|\n|   45395259|           464|\n|   12887339|           426|\n|    3618115|           422|\n|   29141083|           408|\n|   52496677|           393|\n|   13679703|           391|\n|    6212523|           365|\n|   52042479|           360|\n|   31759399|           346|\n|   50579062|           330|\n+-----------+--------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"vine_table\"."],"metadata":{"id":"8SbTasxbuXGK","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7bae67f8-bd73-4da7-89bf-a318f05747c7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Create the \"vine_df\" DataFrame that has the \"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", and \"vine\" columns. \nvine_df = df.select([\"review_id\",\"star_rating\",\"helpful_votes\", \"total_votes\",\"vine\"])\nvine_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHQKbmCE2p3Q","outputId":"5226601d-26b3-4853-f69f-3fc9bec82369","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6b6d83d5-0d22-4da7-869b-9da666817d66","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------+-----------+-------------+-----------+----+\n|     review_id|star_rating|helpful_votes|total_votes|vine|\n+--------------+-----------+-------------+-----------+----+\n| R8EWA1OFT84NX|          5|            0|          0|   N|\n|R2JWY4YRQD4FOP|          5|            0|          0|   N|\n| RL5ESX231LZ0B|          5|            0|          0|   N|\n| RRMS9ZWJ2KD08|          5|            0|          0|   N|\n|R14I3ZG5E6S7YM|          5|            0|          0|   N|\n|R13EPSFP5DODN5|          4|            0|          0|   N|\n| R6RBP4HTE67SY|          5|            0|          0|   N|\n|R15B3EU40RSU2W|          5|            0|          0|   N|\n| RP4DD53A4ZJA2|          5|            0|          0|   N|\n|R2C99DJEO4RZ4K|          5|            3|          4|   N|\n| REV51EW323H8W|          5|            0|          0|   N|\n|R2GQ3W03WIUZKE|          5|            0|          0|   N|\n| RTI1YI7K6GE3D|          5|            0|          0|   N|\n|R3V9C2C0SPSZU6|          5|            0|          0|   N|\n|R1LB42XCSSCLV6|          5|            0|          0|   N|\n|R113NWCW6STTMC|          5|            0|          0|   N|\n| RWRN5XK337N41|          1|            0|          0|   N|\n| RF4WL3QEP3PVI|          1|            0|          0|   N|\n|R2DRL5NRODVQ3Z|          5|            2|          2|   N|\n|R3T9B92MDDHKMM|          2|            5|          5|   N|\n+--------------+-----------+-------------+-----------+----+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["# Load"],"metadata":{"id":"I8aTsEjZ2s6L","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11baae85-fb35-4462-a995-baefcbb0ab67","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["mode = \"append\"\njdbc_url=\"jdbc:postgresql://<endpointredactedforsecurity>:5432/rds_database\"\nconfig = {\"user\":\"postgres\", \"password\": \"password\", \"driver\":\"org.postgresql.Driver\"}"],"metadata":{"id":"W4dzUKfI2vXM","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"693ab1fc-6064-4198-8959-d5cf4f4a1838","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write review_id_df to table in RDS\nreview_id_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"],"metadata":{"id":"iOxKqMsD2yVs","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6e709227-f1b9-47ba-94e4-304058e96291","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-2977815509487994>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Write review_id_df to table in RDS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mreview_id_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjdbc_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'review_id_table'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36mjdbc\u001B[0;34m(self, url, table, mode, properties)\u001B[0m\n\u001B[1;32m   1470\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1471\u001B[0m             \u001B[0mjprop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetProperty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1472\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjprop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1473\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1474\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o500.jdbc.\n: org.postgresql.util.PSQLException: The authentication type 10 is not supported. Check that you have configured the pg_hba.conf file to include the client's IP address or subnet, and that it is using an authentication scheme supported by the driver.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:614)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:222)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:194)\n\tat org.postgresql.Driver.makeConnection(Driver.java:450)\n\tat org.postgresql.Driver.connect(Driver.java:252)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:94)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:63)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:96)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:259)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:211)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:167)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:166)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:156)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:299)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:249)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:469)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:439)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:312)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:908)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n","errorSummary":"org.postgresql.util.PSQLException: The authentication type 10 is not supported. Check that you have configured the pg_hba.conf file to include the client's IP address or subnet, and that it is using an authentication scheme supported by the driver.","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-2977815509487994>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Write review_id_df to table in RDS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mreview_id_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjdbc_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'review_id_table'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36mjdbc\u001B[0;34m(self, url, table, mode, properties)\u001B[0m\n\u001B[1;32m   1470\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1471\u001B[0m             \u001B[0mjprop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetProperty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1472\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjprop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1473\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1474\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o500.jdbc.\n: org.postgresql.util.PSQLException: The authentication type 10 is not supported. Check that you have configured the pg_hba.conf file to include the client's IP address or subnet, and that it is using an authentication scheme supported by the driver.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:614)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:222)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:194)\n\tat org.postgresql.Driver.makeConnection(Driver.java:450)\n\tat org.postgresql.Driver.connect(Driver.java:252)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:94)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:63)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:96)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:259)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:211)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:167)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:166)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:156)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:299)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:249)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:469)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:439)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:312)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:908)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Write products_df to table in RDS\nproducts_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"],"metadata":{"id":"pPXyGVE-2yPJ","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"779f52e1-3a15-4386-8171-3f5657fd2a21","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write customers_df to table in RDS\ncustomers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"],"metadata":{"id":"aHbca4zN2yIa","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"55cedb42-70ca-4fb3-a262-d3bbf5f7d29d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write vine_df to table in RDS\nvine_table_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"],"metadata":{"id":"2HfOFneW2x_F","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3c0ebd32-1363-4898-8355-176a154413f1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.8","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"part_one_starter_code","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2977815509487976}},"nbformat":4,"nbformat_minor":0}
