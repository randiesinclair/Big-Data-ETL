{"cells":[{"cell_type":"code","source":["# Activate Spark in our Colab notebook.\nimport os\n# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n# For example:\n# spark_version = 'spark-3.2.2'\nspark_version = 'spark-3.2.3'\nos.environ['SPARK_VERSION']=spark_version\n\n# Install Spark and Java\n!apt-get update\n!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n!pip install -q findspark\n\n# Set Environment Variables\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n\n# Start a SparkSession\nimport findspark\nfindspark.init()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8eFW_wl1n39","outputId":"9a3c780e-fa40-416c-c653-7e8254d85497","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"009369f4-daaa-42c9-8a2e-c4ca4e282d7c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://repos.azul.com/zulu/deb stable InRelease\r\n\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)]\r                                                                           \rHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\r\n\r                                                                           \r0% [Connected to security.ubuntu.com (91.189.91.38)]\r                                                    \r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\r\n\r                                              \r0% [Waiting for headers]\r                        \rHit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\r\n\r0% [Waiting for headers]\r                        \rHit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\r\n\r                        \r0% [Working]\r0% [Working]\r0% [Working]\r0% [Working]\r20% [Working]\r             \r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 4%\r\rReading package lists... 4%\r\rReading package lists... 5%\r\rReading package lists... 5%\r\rReading package lists... 47%\r\rReading package lists... 48%\r\rReading package lists... 48%\r\rReading package lists... 49%\r\rReading package lists... 49%\r\rReading package lists... 60%\r\rReading package lists... 60%\r\rReading package lists... 69%\r\rReading package lists... 69%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 84%\r\rReading package lists... 84%\r\rReading package lists... 92%\r\rReading package lists... 92%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 99%\r\rReading package lists... 99%\r\rReading package lists... Done\r\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 23.0.1 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"]}],"execution_count":0},{"cell_type":"code","source":["# Get postgresql package\n!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzCrgs0Z1rnw","outputId":"ec69bc40-e6fc-4df3-a738-9d90f097775a","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d63b8cae-d5e3-4c6b-a77e-55c8cb899c09","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["--2023-03-16 06:45:43--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\r\nResolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\r\nConnecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 914037 (893K) [application/java-archive]\r\nSaving to: ‘postgresql-42.2.9.jar.3’\r\n\r\n\rpostgresql-42.2.9.j   0%[                    ]       0  --.-KB/s               \rpostgresql-42.2.9.j  27%[====>               ] 247.71K  1.01MB/s               \rpostgresql-42.2.9.j 100%[===================>] 892.61K  2.61MB/s    in 0.3s    \r\n\r\n2023-03-16 06:45:44 (2.61 MB/s) - ‘postgresql-42.2.9.jar.3’ saved [914037/914037]\r\n\r\n"]}],"execution_count":0},{"cell_type":"code","source":["# Import Spark and create a SparkSession\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"BigData-HW-1\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"],"metadata":{"id":"0DuBth0V2PR8","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8cfefb38-34cf-4331-9dd0-df803541ba5f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Extract the Amazon Data into Spark DataFrame"],"metadata":{"id":"D3W2XJVi2CU-","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c1df816-2c55-43cc-ab3d-a3c11f0327d3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Read in the data from an S3 Bucket\nfrom pyspark import SparkFiles\nurl = \"s3://bigdata-etl-randie/amazon_reviews_us_Baby_v1_00.tsv\"\nspark.sparkContext.addFile(url)\n\ndf = spark.read.option('header', 'true').csv(url, sep='\\t', inferSchema=True)\ndf.show(20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Na_stw7b1wfU","outputId":"5b1ef517-c203-47d2-abc2-aca40b24098d","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8ad69a0c-212f-4944-9220-76a5bb311f5c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n|         US|    9970739| R8EWA1OFT84NX|B00GSP5D94|     329991347|Summer Infant Swa...|            Baby|          5|            0|          0|   N|                Y|Great swaddled bl...|Loved these swadd...| 2015-08-31|\n|         US|   23538442|R2JWY4YRQD4FOP|B00YYDDZGU|     646108902|Pacifier Clip Gir...|            Baby|          5|            0|          0|   N|                N|Too cute and real...|These are adorabl...| 2015-08-31|\n|         US|    8273344| RL5ESX231LZ0B|B00BUBNZC8|     642922361|Udder Covers - Br...|            Baby|          5|            0|          0|   N|                Y|          Five Stars|          Great gift| 2015-08-31|\n|         US|   24557753| RRMS9ZWJ2KD08|B00AWLZFTS|     494272733|Gerber Graduates ...|            Baby|          5|            0|          0|   N|                Y|Cute; wash up nic...|These forks are g...| 2015-08-31|\n|         US|   46263340|R14I3ZG5E6S7YM|B00KM60D3Q|     305813185|Summer Infant Ult...|            Baby|          5|            0|          0|   N|                Y|            Love it!|I wanted somethin...| 2015-08-31|\n|         US|   24557753|R13EPSFP5DODN5|B00PQMRZG4|     607341708|Summer Infant Kee...|            Baby|          4|            0|          0|   N|                Y|        Rips easily.|Loved with daught...| 2015-08-31|\n|         US|   33520065| R6RBP4HTE67SY|B005DL5970|     971881542|Natural HE Powder...|            Baby|          5|            0|          0|   N|                Y|Cloth Diaper Dete...|This is a great d...| 2015-08-31|\n|         US|   20241560|R15B3EU40RSU2W|B00C6D2WL4|      93827401|Dr. Brown's Bottl...|            Baby|          5|            0|          0|   N|                Y|          Five Stars|                good| 2015-08-31|\n|         US|    9987983| RP4DD53A4ZJA2|B0083973FK|     958629336|Sposie Booster Pa...|            Baby|          5|            0|          0|   N|                Y|          Five Stars|With these my mil...| 2015-08-31|\n|         US|   52570308|R2C99DJEO4RZ4K|B00RLYG2S2|     147324304|Abiie Beyond Wood...|            Baby|          5|            3|          4|   N|                Y|So far I love thi...|So far I love thi...| 2015-08-31|\n|         US|    9287389| REV51EW323H8W|B010UX9T5I|     446691106|Lovinglove Baby G...|            Baby|          5|            0|          0|   N|                Y|          Five Stars|           Love them| 2015-08-31|\n|         US|   32840762|R2GQ3W03WIUZKE|B00VWBY7SC|     271204734|Bugzi Stroller Ho...|            Baby|          5|            0|          0|   N|                Y|Love these hooks ...|Love these hooks ...| 2015-08-31|\n|         US|    7797182| RTI1YI7K6GE3D|B006ZBPH24|      67911244|Born Free 5 oz. B...|            Baby|          5|            0|          0|   N|                Y|          Five Stars|           very good| 2015-08-31|\n|         US|   14788115|R3V9C2C0SPSZU6|B00UGV8BEU|     613360092|Baby Bandana Bibs...|            Baby|          5|            0|          0|   N|                Y|            Perfect!|Love these bibs! ...| 2015-08-31|\n|         US|   37909065|R1LB42XCSSCLV6|B005BIOOYO|     527977399|Flip Stay-Dry Ins...|            Baby|          5|            0|          0|   N|                Y|best inserts for ...|I love these. The...| 2015-08-31|\n|         US|   15935520|R113NWCW6STTMC|B0071D1AKI|     634188771|Aqueduck The ORIG...|            Baby|          5|            0|          0|   N|                Y|        Very Helpful|This worked exact...| 2015-08-31|\n|         US|   16308044| RWRN5XK337N41|B00M2F0OYS|     166133791|Motorola Baby Mon...|            Baby|          1|            0|          0|   N|                N|Very Dissapointed...|I am so disappoin...| 2015-08-31|\n|         US|    8168178| RF4WL3QEP3PVI|B00QCBD5AS|     294351494|Minnie Mouse Delu...|            Baby|          1|            0|          0|   N|                Y|            One Star|Ordered minnie mo...| 2015-08-31|\n|         US|   23299101|R2DRL5NRODVQ3Z|B00SN6F9NG|       3470998|Rhoost Nail Clipp...|            Baby|          5|            2|          2|   N|                Y|If fits so comfor...|This is an absolu...| 2015-08-31|\n|         US|   14261025|R3T9B92MDDHKMM|B00J0YTS1E|     488640919|My Natural Owl Mu...|            Baby|          2|            5|          5|   N|                Y|Used to be great....|They changed the ...| 2015-08-31|\n+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# Get the number of rows in the DataFrame.\ndf.count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cayz-3Q52IM3","outputId":"5d19aeec-223a-4372-f773-f74ab1aabc62","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f638bd6c-a7c8-4209-a066-aa2852cd2750","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[57]: 1752932"]}],"execution_count":0},{"cell_type":"markdown","source":["# Transform the Data"],"metadata":{"id":"C9U0rkGZ2eu7","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3d32962-5517-451c-aee8-e5be34ca43d5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Examine the Schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae45ce87-f3d0-4776-ad46-0acd8496a5b9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"515f22b3-6c1c-4edf-aaa0-b79ea81312bf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- marketplace: string (nullable = true)\n |-- customer_id: integer (nullable = true)\n |-- review_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- product_parent: integer (nullable = true)\n |-- product_title: string (nullable = true)\n |-- product_category: string (nullable = true)\n |-- star_rating: integer (nullable = true)\n |-- helpful_votes: integer (nullable = true)\n |-- total_votes: integer (nullable = true)\n |-- vine: string (nullable = true)\n |-- verified_purchase: string (nullable = true)\n |-- review_headline: string (nullable = true)\n |-- review_body: string (nullable = true)\n |-- review_date: string (nullable = true)\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"review_id_table\"."],"metadata":{"id":"dUoftWoKtM_c","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"73f7fe05-6f1c-4bce-b8e2-eeeed5a44377","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import to_date\n# Create the \"review_id_df\" DataFrame with the appropriate columns and data types.\nreview_id_table = df.select([\"review_id\",\"customer_id\",\"product_id\", \"product_parent\",\"review_date\"])\nreview_id_table.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tMYkSIk2d-m","outputId":"e090226f-d7f3-4319-c47f-8a4fc9a69c09","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5c9163d6-d607-4d18-bfa9-fc7de5c61335","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------+-----------+----------+--------------+-----------+\n|     review_id|customer_id|product_id|product_parent|review_date|\n+--------------+-----------+----------+--------------+-----------+\n| R8EWA1OFT84NX|    9970739|B00GSP5D94|     329991347| 2015-08-31|\n|R2JWY4YRQD4FOP|   23538442|B00YYDDZGU|     646108902| 2015-08-31|\n| RL5ESX231LZ0B|    8273344|B00BUBNZC8|     642922361| 2015-08-31|\n| RRMS9ZWJ2KD08|   24557753|B00AWLZFTS|     494272733| 2015-08-31|\n|R14I3ZG5E6S7YM|   46263340|B00KM60D3Q|     305813185| 2015-08-31|\n|R13EPSFP5DODN5|   24557753|B00PQMRZG4|     607341708| 2015-08-31|\n| R6RBP4HTE67SY|   33520065|B005DL5970|     971881542| 2015-08-31|\n|R15B3EU40RSU2W|   20241560|B00C6D2WL4|      93827401| 2015-08-31|\n| RP4DD53A4ZJA2|    9987983|B0083973FK|     958629336| 2015-08-31|\n|R2C99DJEO4RZ4K|   52570308|B00RLYG2S2|     147324304| 2015-08-31|\n| REV51EW323H8W|    9287389|B010UX9T5I|     446691106| 2015-08-31|\n|R2GQ3W03WIUZKE|   32840762|B00VWBY7SC|     271204734| 2015-08-31|\n| RTI1YI7K6GE3D|    7797182|B006ZBPH24|      67911244| 2015-08-31|\n|R3V9C2C0SPSZU6|   14788115|B00UGV8BEU|     613360092| 2015-08-31|\n|R1LB42XCSSCLV6|   37909065|B005BIOOYO|     527977399| 2015-08-31|\n|R113NWCW6STTMC|   15935520|B0071D1AKI|     634188771| 2015-08-31|\n| RWRN5XK337N41|   16308044|B00M2F0OYS|     166133791| 2015-08-31|\n| RF4WL3QEP3PVI|    8168178|B00QCBD5AS|     294351494| 2015-08-31|\n|R2DRL5NRODVQ3Z|   23299101|B00SN6F9NG|       3470998| 2015-08-31|\n|R3T9B92MDDHKMM|   14261025|B00J0YTS1E|     488640919| 2015-08-31|\n+--------------+-----------+----------+--------------+-----------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"products\" Table"],"metadata":{"id":"aAVCFjXhtXO8","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"37315176-2e56-4333-a0fb-6f21db856b03","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Create the \"products_df\" DataFrame that drops the duplicates in the \"product_id\" and \"product_title columns. \nproducts_df = df.select([\"product_id\",\"product_title\"])\nproducts_df = products_df.dropDuplicates()\nproducts_df.show()"],"metadata":{"id":"g9gTNhT62je4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c6e97a7-c616-4229-e2f3-29e043b53833","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e8c5d4eb-f7e4-4f9e-8c55-2e8caafb9502","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+--------------------+\n|product_id|       product_title|\n+----------+--------------------+\n|B00VWBY7SC|Bugzi Stroller Ho...|\n|B00YYDDZGU|Pacifier Clip Gir...|\n|B00KM60D3Q|Summer Infant Ult...|\n|B005DL5970|Natural HE Powder...|\n|B00M2F0OYS|Motorola Baby Mon...|\n|B010UX9T5I|Lovinglove Baby G...|\n|B00BUBNZC8|Udder Covers - Br...|\n|B00GSP5D94|Summer Infant Swa...|\n|B00PQMRZG4|Summer Infant Kee...|\n|B0071D1AKI|Aqueduck The ORIG...|\n|B0083973FK|Sposie Booster Pa...|\n|B00J0YTS1E|My Natural Owl Mu...|\n|B00C6D2WL4|Dr. Brown's Bottl...|\n|B005BIOOYO|Flip Stay-Dry Ins...|\n|B00AWLZFTS|Gerber Graduates ...|\n|B00UGV8BEU|Baby Bandana Bibs...|\n|B00SN6F9NG|Rhoost Nail Clipp...|\n|B00RLYG2S2|Abiie Beyond Wood...|\n|B0070U6R9Q|NUK Hello Kitty S...|\n|B00QCBD5AS|Minnie Mouse Delu...|\n+----------+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"customers\" Table"],"metadata":{"id":"LJHuZ9zut0e5","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c4dcd777-53cd-4af1-8807-ddde6c49be90","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import count\nfrom pyspark.sql.functions import desc\n\n# Create the \"customers_df\" DataFrame that groups the data on the \"customer_id\" by the number of times a customer reviewed a product. \ncustomers_df = df.groupBy(\"customer_id\").agg(count(\"*\").alias(\"customer_count\"))\ncustomers_df = customers_df.orderBy(desc(\"customer_count\"))\ncustomers_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_pF2Vf3c2n2O","outputId":"9214d06e-83e1-40cf-d209-e1a571ba03cc","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e36df0d-3626-4e68-9eaa-4f31e0bfdd18","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------+--------------+\n|customer_id|customer_count|\n+-----------+--------------+\n|   12084007|           192|\n|   51591392|           141|\n|   49633579|           140|\n|   52457037|           114|\n|   13103726|           112|\n|   51983887|           109|\n|   31461331|           105|\n|   46106653|           105|\n|   46137405|           105|\n|   14389539|           102|\n|   52097584|           101|\n|   43715603|            99|\n|   13404682|            98|\n|   45725380|            98|\n|   48428870|            93|\n|   31546953|            90|\n|   38555595|            89|\n|   46912614|            87|\n|   48384094|            86|\n|   44893973|            85|\n+-----------+--------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Create the \"vine_table\"."],"metadata":{"id":"8SbTasxbuXGK","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7bae67f8-bd73-4da7-89bf-a318f05747c7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Create the \"vine_df\" DataFrame that has the \"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", and \"vine\" columns. \nvine_df = df.select([\"review_id\",\"star_rating\",\"helpful_votes\", \"total_votes\",\"vine\"])\nvine_df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHQKbmCE2p3Q","outputId":"5226601d-26b3-4853-f69f-3fc9bec82369","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6b6d83d5-0d22-4da7-869b-9da666817d66","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------+-----------+-------------+-----------+----+\n|     review_id|star_rating|helpful_votes|total_votes|vine|\n+--------------+-----------+-------------+-----------+----+\n| R8EWA1OFT84NX|          5|            0|          0|   N|\n|R2JWY4YRQD4FOP|          5|            0|          0|   N|\n| RL5ESX231LZ0B|          5|            0|          0|   N|\n| RRMS9ZWJ2KD08|          5|            0|          0|   N|\n|R14I3ZG5E6S7YM|          5|            0|          0|   N|\n|R13EPSFP5DODN5|          4|            0|          0|   N|\n| R6RBP4HTE67SY|          5|            0|          0|   N|\n|R15B3EU40RSU2W|          5|            0|          0|   N|\n| RP4DD53A4ZJA2|          5|            0|          0|   N|\n|R2C99DJEO4RZ4K|          5|            3|          4|   N|\n| REV51EW323H8W|          5|            0|          0|   N|\n|R2GQ3W03WIUZKE|          5|            0|          0|   N|\n| RTI1YI7K6GE3D|          5|            0|          0|   N|\n|R3V9C2C0SPSZU6|          5|            0|          0|   N|\n|R1LB42XCSSCLV6|          5|            0|          0|   N|\n|R113NWCW6STTMC|          5|            0|          0|   N|\n| RWRN5XK337N41|          1|            0|          0|   N|\n| RF4WL3QEP3PVI|          1|            0|          0|   N|\n|R2DRL5NRODVQ3Z|          5|            2|          2|   N|\n|R3T9B92MDDHKMM|          2|            5|          5|   N|\n+--------------+-----------+-------------+-----------+----+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["# Load"],"metadata":{"id":"I8aTsEjZ2s6L","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11baae85-fb35-4462-a995-baefcbb0ab67","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["mode = \"append\"\njdbc_url=\"jdbc:postgresql://<endpointredactedforsecurity>:5432/rds_database\"\nconfig = {\"user\":\"postgres\", \"password\": \"password\", \"driver\":\"org.postgresql.Driver\"}"],"metadata":{"id":"W4dzUKfI2vXM","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"693ab1fc-6064-4198-8959-d5cf4f4a1838","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write review_id_df to table in RDS\nreview_id_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"],"metadata":{"id":"iOxKqMsD2yVs","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6e709227-f1b9-47ba-94e4-304058e96291","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-2977815509487994>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Write review_id_df to table in RDS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mreview_id_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjdbc_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'review_id_table'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36mjdbc\u001B[0;34m(self, url, table, mode, properties)\u001B[0m\n\u001B[1;32m   1470\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1471\u001B[0m             \u001B[0mjprop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetProperty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1472\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjprop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1473\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1474\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o500.jdbc.\n: org.postgresql.util.PSQLException: The authentication type 10 is not supported. Check that you have configured the pg_hba.conf file to include the client's IP address or subnet, and that it is using an authentication scheme supported by the driver.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:614)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:222)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:194)\n\tat org.postgresql.Driver.makeConnection(Driver.java:450)\n\tat org.postgresql.Driver.connect(Driver.java:252)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:94)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:63)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:96)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:259)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:211)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:167)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:166)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:156)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:299)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:249)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:469)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:439)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:312)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:908)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n","errorSummary":"org.postgresql.util.PSQLException: The authentication type 10 is not supported. Check that you have configured the pg_hba.conf file to include the client's IP address or subnet, and that it is using an authentication scheme supported by the driver.","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-2977815509487994>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Write review_id_df to table in RDS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mreview_id_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjdbc_url\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'review_id_table'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36mjdbc\u001B[0;34m(self, url, table, mode, properties)\u001B[0m\n\u001B[1;32m   1470\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1471\u001B[0m             \u001B[0mjprop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetProperty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mproperties\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1472\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjdbc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjprop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1473\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1474\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o500.jdbc.\n: org.postgresql.util.PSQLException: The authentication type 10 is not supported. Check that you have configured the pg_hba.conf file to include the client's IP address or subnet, and that it is using an authentication scheme supported by the driver.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:614)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:222)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:194)\n\tat org.postgresql.Driver.makeConnection(Driver.java:450)\n\tat org.postgresql.Driver.connect(Driver.java:252)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:94)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:63)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:96)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:259)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:211)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:167)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:166)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:156)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:299)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:249)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1080)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:469)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:439)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:312)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:908)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Write products_df to table in RDS\nproducts_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"],"metadata":{"id":"pPXyGVE-2yPJ","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"779f52e1-3a15-4386-8171-3f5657fd2a21","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write customers_df to table in RDS\ncustomers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"],"metadata":{"id":"aHbca4zN2yIa","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"55cedb42-70ca-4fb3-a262-d3bbf5f7d29d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Write vine_df to table in RDS\nvine_table_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"],"metadata":{"id":"2HfOFneW2x_F","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3c0ebd32-1363-4898-8355-176a154413f1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.8","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"part_one_starter_code","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2977815509487976}},"nbformat":4,"nbformat_minor":0}
